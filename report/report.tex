%\documentclass{article}
\documentclass{IEEEtran}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{csquotes}
\usepackage[style=nature]{biblatex}
\addbibresource{references.bib}

\title{Assessing quality of music generated by the Music Transformer with an American Folk dataset \\
    \normalsize{\url{github.com/gregwinther/folk_transformer}}}
%\author{Tom F. Hansen, Bjørn Iversen and Sebastian G. Winther-Larsen}

\author{\IEEEauthorblockN{Sebastian G. Winther-Larsen}
\IEEEauthorblockA{\textit{Institute of Informatics, University of Oslo} \\
}
\and
\IEEEauthorblockN{Tom F. Hansen}
\IEEEauthorblockA{\textit{Institute of Informatics, University of Oslo} \\
}
\and
\IEEEauthorblockN{Bjørn Iversen}
\IEEEauthorblockA{\textit{Institute of Informatics, University of Oslo} \\
}
}


\begin{document}
    \maketitle

    \begin{abstract}
        Here we will write the abstract.

        \end{abstract}
        
        \begin{IEEEkeywords}
        music generation, transformer model, evaluation, transfer learning, Americana
        \end{IEEEkeywords}

    \section{Motivation and introduction}

        The Transformer model, implementing the attention principle~\cite{vaswani2017attention},
        is today recognised as the best performing sequential machine learning model,
        surpassing RNN-based models in most cases, mainly argued by its better abilities
        to remember long term coherence, shorter training time and applicability in transfer learning.
        While originally used primarly for NLP, which today has mature implementations,
        the architecture can also be applied for other sequential models, such as music generation~\cite{huang2018music}.
        The music transformer developed in the Magenta project is trained on the Maestro
        dataset~\cite{maestrodataset}.
        By setting a primer – a start music sequence, the model generates new music with good
        results along the same lines as the training set. With other primers than regular and
        systematic classical music in Maestro, the quality of the output is varying.
        
        Motivated by generating more irregular music, the main aim of the paper is
        to describe a framework for the quality assessment of different approaches to the generation 
        of music with the transformer model. By building, what is supposed to be the same 
        music generator, but with different approaches, the evaluation framework will assess 
        the quality of each approach. It is not known to the authors scientific papers
        describing such a comparison of music transformers, other than the normal
        comparison of music generated by RNNs and transformers ~\cite{huang2018music}.
        At the core of such an architecture is, for each approach; 1) in order to make a fair comparison,
        a detailed description of model topology, its tuning parameters, and the size
        and structure of the dataset used for training, and 2) an evaluation format
        that combines a form of quantitative and qualitative evaluation technique.
       
        To this end, we wish to employ the transformer music to a subgenre of music   
        to which such a model has not been extensively applied.
        While initial findings from applying the transformer to jazz music has shown 
        some limitations~\cite{wu2020jazz}, while applying LSTM networks to Blues has 
        been moderately succesful~\cite{eck2002bluesLSTM} and applying the transformer 
        model to pop music seems to work well~\cite{huang2020pop}.
        From a music theory standpoint this is very sensible - classical music often has 
        formal rules, the epitome of which is the fugue~\cite{giraud2015computational};
        and pop music follows some very clear norms~\cite{hennion1983production}. While 
        even Free Jazz has \emph{some} rules, it readily falls into the category of the 
        type of rhytmic music with the least amount of structure, per the definition
        that it is ``characterized by the absence of set chord patterns or
        time patterns''\cite{FreeJazz}.

        American roots music, encompassing spirituals, cajun music, cowboy music, work songs,
        but also early blues such as Dixieland; from now on referred to as ``Americana'', presents 
        itself as hitherto unexplored territory. It also provides a nice stepping stone
        towards more ``unstructured'' music as it often allows for improvisationg, but 
        otherwise retains a relatively rigid structure~\cite{libcong}.
        We have therefor collected a dataset of MIDI files of Americana music, which we
        will use in our quality assessment framework.

    \section{Related work}
       The transformer model is considered state of the art in music generation,
       surpassing RNN-based models in the last few years. Both are sequential models,
       but the attention principle at the core of the transformer facilitates
       remembering coherence over longer sections of sequences and highlights
       especially important sections. From generating music of 10's of seconds with RNN, it is now possible to generate minutes of realistic music ~\cite{huang2018music}. Still there is a lot of unresolved challenges, like generating long sections (over some minutes), in highly irregular compositions
       and multi channel (many instruments) signals. To combat these challenges the
       improvement of the transformer model has high focus in the research community.
       Some of the most recent attempts are the Transformer-XL ~\cite{dai2019transformerxl} 
       model and the Reformer ~\cite{kitaev2020reformer} as a particularly promising candidate. A Reformer model claim to be trained on a standard computer with a single GPu. In this analysis we will utilize the original transformer architecture, as this is the model-architecture in the music transformer from Google.

       \subsection{Music transformers}
       In the few existing papers considering music generation with the \emph{transformer} we want to emphasize some important related works besides the beforementioned music transformer. In the blues transformer 

       nevn blues transformer
       nevn LakhNES
       nevn jazz transformer
       pop music transformer
       Foley music - MIDI from video

       However there is little work on generating intentionally the same music generator with different approaches. Another new approach is to use transfer learning from an existing model.

       \subsection{Evaluation of ML-generated music}
       In the evaluation of models of music generation based on machine learning we would like to point out the works by ~\cite{1030094}, ~\cite{yang2020evaluation} and \cite{wu2020jazz}.

       These works describe either a qualitative evaluation or a qualitative evaluation. In our attempt we combine these 2 approaches and establish a common framework.

    \section{Methods}

        Acting as a base and for exemplification of the benchmark architecture,
        Americana music is generated in 2 different model concepts:
        \begin{enumerate}
            \item Utilize transfer learning with music transformer as a base, and
                    train with the full dataset of Americana midi-files.
            \item Train a new transformer model only using the full Americana dataset
        \end{enumerate} 
        
        The hypothesis is that concept number 1 will result in the best performing model,
        but an important issue is what makes up the best model and how to evaluate such a
        subjective "sequence-result" as music in a fair and trustworthy manner? 
        Some will say this is an impossible task ~\cite{1030094}. Will a transfer learning model be significantly better than only training on a single dataset, such as has been shown in other ML-applications, like image classification \cite{ref}, even though the MAESTRO dataset is totally different from the Americana dataset.

        An attempt to sort this out is by evaluating in a quantitative and qualitative way.
        The quantitative, hence objective, way can shortly be described as a technical
        comparison of the predicted signal and the real signal. Principles by
        \url{https://github.com/RichardYang40148/mgeval}, ~\cite{wu2020jazz} and
         will be utilized.
        
        The qualitative part constitutes an music expert judgement,
        based on listening to the generated music files from the objective evaluation.
        In a second, and survey based part, a large number of random people is asked
        to rate the different music files.
        
        Qualitative and quantitative measures will finally be summarised in a common scheme.
        
    \subsection{Datasets}

    \textbf{MAESTRO}~\cite{maestrodataset}
    (MIDI and Audio Edited for Synchronous TRacks and Organization)
    is a dataset with over 200 hours of virtuosic piano perfomances captured with 
    a fine alignment of approximately 3ms between note lables and audio waveforms.

    The data is a produce from performances in the International Piano-e-competition.
    During each installment of the competiton, vrituoso pianists perform on Yamaha
    Disklaviers which, in addition to being concert-quality acoustic grand pianos,
    utilize integrated high-precision MIDI capture and playback.

    

    Question: How many of the performances are of the same piece?

    \textbf{Americana}
    The Americana dataset contains xxx hours of music in the subgenres xxx.
    
    To make a fair comparison of the datasets we have set up some main statistical figures in table xxx.
    - Number of songs
    - Mean length of songs
    - +++

    \subsection{Model topology and tuning}
    
    \subsection{Qantitative evaluation}
    
    \subsection{Qualitative evaluation}
    
    \section{Results}
    \textbf{Americana generator with transfer learning}
    some tekst

    \textbf{Americana generator in stand alone learning}
    some text
    
    \section{Discussion}
    
    \section{Conclusions and further development}

    \printbibliography

\end{document}
